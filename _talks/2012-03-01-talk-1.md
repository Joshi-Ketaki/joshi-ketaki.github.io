---
title: "Single Application Source, Any Hardware System"
collection: talks
type: "Qualifier Exam Talk"
permalink: /talks/2012-03-01-talk-1
venue: "Yale University, Area Exam Talk"
date: 2021-12-16
location: "New Haven, Connecticut"
---
Today with growing amount of data and availability of different accelerators, it is crucial to maximize system utility in
heterogeneous systems. The fact that companies such as NVIDIA are acquiring Mellanox or Intel acquiring Altera or AMD
buying Xilinx displays the cognizance of industry in maximizing system utilization in heterogeneous architectures by leveraging
all possible compute power from different processors along with traditionally targeted processors for specific workloads.
Optimal system utilization will ensure power efficiency and better application turnaround times. We envision a hardware agnostic
system where any application - irrespective of which architecture it was traditionally targeted for - can run on any hardware
substrate. We start with a smaller system consisting of CPUs and GPUs. In lieu of our above vision, we enable a CUDA application
earlier meant to be run only on GPUs to be able to run on CPU Single Instruction Multiple Data (SIMD) units also. We propose
changes to the CUDA driver and runtime to launch CUDA kernels either on the CPU SIMD units, GPU or split between both
the processors. The challenges here are keeping the application source code as is, achieving this mapping transparently to the
application developer and achieving at-least GPU-comparable performance to make this effort worthwhile while supporting all levels of parallelism. This vision also comes with its own set of memory management issues which we will discuss in detail. We achieved 1.5X better performance compared to an all CPU configuration and 1.3X better performance compared to an all GPU configuration for batched workloads which simulate the data center workloads. This shows that there is promise in characterizing workloads and routing to the correct hardware
substrate. This also shows promise in implementing automated intelligent scheduling techniques to do this hardware mapping
based on runtime properties to give significant performance benefits.
