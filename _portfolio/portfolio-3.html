---
title: "Access Guided Eviction for GPU Memory"
excerpt: "<br/><img src='/images/Memory_Placement_Access_GE.png'> 
<br/>
In CPU-GPU systems, GPUs have lower memory capacity, but higher bandwidth compared to CPU systems. 
Slower interconnects between such devices slow down the memory transfer. To lower memory transfers it is important to keep the data 
closer to the location of the compute."
collection: Portfolio
---
Memory placement is critical in modern heterogeneous systems. These systems face the issue of slow memory transfers. 
Let's look at CPU-GPU systems in particular. In CPU-GPU systems, GPUs have lower memory capacity, but higher bandwidth compared to CPU systems. 
Slower interconnects between such devices slows down the memory transfer. To lower memory transfers it is important to keep the data 
closer to the location of the compute. 

<br/><img src='/images/Memory_Placement_Access_GE.png'> 
<br/>
This highlights the important research question of selecting the right eviction
candidate to make space for new data if the compute node's memory is oversubscribed. A bad eviction policy will evict data which 
is going to be needed in the near future. The existing policy in the CPU-GPU memory management stack was developed when GPUs were used for 
applications that demonstrated streaming access patterns. The existing eviction policy performs poorly on emerging GPU applications such as
graph processing which exhibit irregular or non-streaming access patterns. We proposed a new eviction policy that was access-aware and did not throw out data 
that would be needed in the near future. This new policy achieved a performance improvement of two orders of magnitude. It evicts data that will not be used in the near future and
avoids unnecessary removal and fetch of data that will be used. The old policy removes data that could be needed and generates more evictions as this removed data has to be brought in again. 
The following graph demonstrates the reduction in the number of evictions with the proposed policy compared to the existing baseline which is shown as the red line.

<br/><img src='/images/Results_Rate_Acess_GE.png'> 
<br/>


This talk was based on the work done as a part of the internship at Nvidia in the summer of 2022.
